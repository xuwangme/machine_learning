## 交叉验证（cross validation）

> Author: xuwang
>
> Mail: xuwang.me@gmail.com

------

#### 1. 目的

测试模型预测新数据（未知数据集）的能力，判断是否存在过度拟合或选择偏差等问题。

#### 2. 交叉验证方法

交叉验证方法可以分成了两类：穷举型和非穷举型

##### 2.1 穷举形

穷举型交叉验证方法测试将原始样本分成训练集和验证集的所有可能方法

1. leave-one-out cross validation 留一交叉验证（LOOCV）

   LOOCV的过程和Jackknife（一种重采样方法，可参考重采样笔记）过程类似，

   伪代码如下：

   **Pseudo-Code-Algorithm:**

   ```python
   Input:
   x, {vector of length N with x-values of data points}
   y, {vector of length N with y-values of data points}
   
   Output:
   err, {estimate for the prediction error}
   
   Steps:
   err ← 0
   for i ← 1, . . . , N do
   // define the cross-validation subsets
   x_in ← (x[1], . . . , x[i − 1], x[i + 1], . . . , x[N])
   y_in ← (y[1], . . . , y[i − 1], y[i + 1], . . . , y[N]
   x_out ← x[i]
   y_out ← interpolate(x_in, y_in, x_out, y_out)
   err ← err + (y[i] − y_out)^2
   end for
   err ← err/N
   ```

   LOOCV一共需要计算$C_1^n=n$组数据，因此计算量很大。可以采取并行的方法减少计算时间。同时由于训练数据较多，只有一个数据进行验证，验证模型有效性的变化较大。即对模型的估计受这个验证点的影响较大，如果这个点是奇点。

2. leave-p-out cross validation 留p交叉验证 （LPOCV）

   LPOCV是LOOCV的一般化版本，LOOCV是LPOCV中p=1时的情况。

   LPOCV在样本过多以及p过大时变得不可行，如$p=30, n=100, C_{30}^{100}=3*10^{25}$。

##### 2.2 非穷举型

非穷举型交叉验证方法并不测试将原始样本分成训练集和验证集的所有可能方法

1. k-fold cross validation k折交叉验证

   在k倍交叉验证中, 原始样本集被随机划分为k大小相等的子样本。在k个子样本中, 单个子样本保留，用于作为验证集, 其余的 k-1子样本用作训练数据。然后重复交叉验证过程 k 次， 每个子样本都会被作为验证集一次。

   最后对k次的结果取平均值。与重复随机子采样相比, 这种方法的优点是, 所有样本都用于训练和验证, 每个样本只用于验证一次。通常使用10折交叉验证。当k=n时则变为了一个LOOCV过程。

   **主要是K的选取。太大不行，太小也不行。K小，导致模型bias较大，因为训练数据较少。K大会导致方差较大。K等于n，相当于留一交叉验证。**

   

2. Repeated random sub-sampling validation 重复随机子采样验证

   此方法也称为蒙特卡洛交叉验证。

   在k重交叉验证的基础上还可采用**蒙特卡洛随机采样（Monte-Carlo random sampling）**的方法，**连续多次生成不同的随机子集**划分方案并依次进行交叉验证，最终验证结果将**根据随机次数取平均值**。

   

3. Adversarial validation 对抗验证

   可参考博客：https://blog.csdn.net/weixin_43896398/article/details/84762922

   处理的是，训练集（Train Set）和测试集（Test Set）差异性较大，此时验证集 （Valid Set）已经不适合评价该模型了，因为验证集来源于训练集。所以我们需要一个验证集能够，代表测试集。 

   具体操作：将训练集和测试集分别进行2类别标记。比如，训练集类别设为0，测试集类别为1。然后将这两部分数据进行混合，再分为新的训练集和测试集，使用新的训练集训练一个2分类网络，对新的测试数据进行测试，选择新的测试集里边原来的训练集数据得分进行排序，选出得分最差的所需数量的数据作为我们需要的验证集。为什么这么操作，是因为，我们认为选出的这些数据和测试集最接近。 

   但是得谨慎使用这种技术。因为如果一旦原来的测试数据改变的话，选出来的验证集就很可能不是一个好的验证集了，最好重新选择。

   

4. Cross validation for time Series 时序数据的交叉验证

   对于时间序列问题，我们不能随机打乱数据集，因为第4年或第5年的一些模式有可能跟第3年的不同，对数据集的重复采样会将分离这些趋势，而我们最终可能只是需要对过去几年的进行验证，就不能用k折交叉验证这种方法了。相反，我们可以采用前项链生成交叉验证，如下所示的5倍正向链接策略：

   　　fold 1 : training [1], test [2]

   　　fold 2 : training [1 2], test [3]

   　　fold 3 : training [1 2 3], test [4]

   　　fold 4 : training [1 2 3 4], test [5]

   　　fold 5 : training [1 2 3 4 5], test [6]

   　　1，2，3，4，5，6代表的是年份。

   

   








